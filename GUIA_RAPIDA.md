# üöÄ GU√çA R√ÅPIDA PARA EL PROFESOR

Pasos para descargar, instalar y ejecutar **Escriba M√©dico Soberano** en tu equipo.

## 1. Clonar el Repositorio

```powershell
git clone https://github.com/Seiksssss/escriba-tfm-min.git
cd escriba-tfm-min
```

## 2. Instalar Ollama (OBLIGATORIO)

Descarga e instala Ollama desde: **https://ollama.com/download**

Una vez instalado, abre una terminal PowerShell y ejecuta:

```powershell
ollama serve
```

D√©jalo corriendo (es el servidor de modelos).

## 3. En OTRA terminal: Descargar Modelo Aloe-Beta-8B

```powershell
ollama pull hf.co/mradermacher/Llama3.1-Aloe-Beta-8B-GGUF:Q4_K_M
```

Esto tardar√° unos 5-10 minutos (descarga ~5-7 GB).

## 3b. (IMPORTANTE) Crear Modelo Personalizado con Prompt M√©dico

```powershell
ollama create escriba-aloe-v3 -f Modelfile
```

Este comando crea el modelo personalizado que usar√° la app. **Sin este paso, no tendr√° el prompt m√©dico especializado.**

## 4. Instalar Dependencias de Python

En la misma terminal (con Ollama a√∫n corriendo):

```powershell
python -m venv .venv
.\.venv\Scripts\Activate.ps1
pip install -r requirements.txt
python -m spacy download es_core_news_sm
```

## 5. Ejecutar la App

```powershell
streamlit run app.py
```

Se abrir√° autom√°ticamente en tu navegador (http://localhost:8501).

---

## ‚úÖ ¬øQu√© deber√≠a ver?

1. **UI Streamlit** con t√≠tulo "ü©∫ Escriba M√©dico Soberano v0.9"
2. **Barra lateral** con:
   - Informaci√≥n del Sistema (GPU, RAM)
   - Estado de Ollama (debe decir "‚úÖ Conectado")
   - Selector de modelo (por defecto: **escriba-aloe-v3** ‚Üê modelo personalizado con prompt m√©dico)

## üìÅ Archivos Importantes

- `MODELO_ALOE_BETA.md`: Instrucciones detalladas del modelo
- `README.md`: Documentaci√≥n completa del proyecto
- `app.py`: Aplicaci√≥n principal
- `data/conversaciones/`: Audios de prueba (conv1.mp3, conv2.mp3, etc.)

## üß™ Probar la App

1. Sube uno de los audios de prueba: `data/conversaciones/conv1.mp3`
2. Haz clic en **"üîÑ Procesar TODO"**
3. Espera a que se complete (transcripci√≥n ‚Üí informe ‚Üí auditor√≠a)

---

## ‚ö†Ô∏è Requisitos M√≠nimos

- **Windows 10+, macOS o Linux**
- **Python 3.11**
- **RAM:** 16 GB (m√≠nimo)
- **GPU NVIDIA** (opcional pero recomendado)
- **Conexi√≥n a internet** (solo para descargas iniciales)

## üÜò Soluci√≥n de Problemas

| Problema | Soluci√≥n |
|----------|----------|
| "ollama command not found" | Reinicia la terminal despu√©s de instalar Ollama |
| "Connection refused" a Ollama | Verifica que `ollama serve` est√© corriendo en otra terminal |
| App lenta / no responde | Aseg√∫rate de tener RAM suficiente (16+ GB) |
| Modelo no se descarga | Ejecuta manualmente: `ollama pull hf.co/mradermacher/Llama3.1-Aloe-Beta-8B-GGUF:Q4_K_M` |

## üìû Contacto

Repositorio: https://github.com/Seiksssss/escriba-tfm-min

---

**¬°Listo!** Si todo va bien, deber√≠as poder transcribir audios y generar notas SOAP autom√°ticamente. üéâ
